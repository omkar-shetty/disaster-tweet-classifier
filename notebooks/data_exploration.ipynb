{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39039a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from itertools import chain\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69bbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(os.getcwd()).parents[1].joinpath('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8776b3be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(data_folder.joinpath('train.csv'))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b47882",
   "metadata": {},
   "source": [
    "## Check skewdness of target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da57a60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.57034\n",
       "1    0.42966\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts()/len(train_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8360a061",
   "metadata": {},
   "source": [
    "Looks like 43% of the tweets are actually related to disasters, so from this dataset it doesn't look like class imbalance is a big issue.  \n",
    "However, for a real life sample of tweets, a more significant class imbalance might be realistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eafb97",
   "metadata": {},
   "source": [
    "## Significance of the variable location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a3e1a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.66728\n",
       "True     0.33272\n",
       "Name: location, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['location'].isna().value_counts()/len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0428695",
   "metadata": {},
   "source": [
    "About 66% of the data has a valid location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4436199",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['valid_location'] = np.where(train_df['location'].isna(), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f805377e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valid_location</th>\n",
       "      <th>sum_target</th>\n",
       "      <th>length</th>\n",
       "      <th>prop_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1075</td>\n",
       "      <td>2533</td>\n",
       "      <td>0.424398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2196</td>\n",
       "      <td>5080</td>\n",
       "      <td>0.432283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valid_location  sum_target  length  prop_target\n",
       "0               0        1075    2533     0.424398\n",
       "1               1        2196    5080     0.432283"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_agg = train_df.groupby('valid_location').agg(sum_target = ('target', np.sum),\n",
    "                                    length = ('target', len)).reset_index()\n",
    "train_agg['prop_target'] = train_agg['sum_target']/train_agg['length']\n",
    "train_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ffe12",
   "metadata": {},
   "source": [
    "The presence of location in and of itself does not seem to be a good indicator of whether the tweet was associated with an actual disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db03d342",
   "metadata": {},
   "source": [
    "## Keyword Variable\n",
    "In comparison, the keyword variable seems to be populated for most of the tweets with a large majority of the tweets (seemingly) related to disasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a03ef558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.991987\n",
       "True     0.008013\n",
       "Name: keyword, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['keyword'].isna().value_counts()/len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ae5d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['keyword'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd84d468",
   "metadata": {},
   "source": [
    "It can also be observed that a lot of the keywords (as shown in the example below) are related to the same root word ('wreck' in the example below). Generating the lemmas for these key words can help further filter down these key words and identify relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dcf0d8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wreckage    39\n",
       "wrecked     39\n",
       "wreck       37\n",
       "Name: keyword, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df['keyword'].str.contains('wreck', na=False), 'keyword'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeaae69",
   "metadata": {},
   "source": [
    "## Unique Tweet Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991116cd",
   "metadata": {},
   "source": [
    "It is also observed that around 69 tweets have been included multiple times in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ce0c892",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>11-Year-Old Boy Charged With Manslaughter of T...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>#Bestnaijamade: 16yr old PKK suicide bomber wh...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>The Prophet (peace be upon him) said 'Save you...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3589</th>\n",
       "      <td>He came to a land which was engulfed in tribal...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4589</th>\n",
       "      <td>Madhya Pradesh Train Derailment: Village Youth...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  count\n",
       "646   11-Year-Old Boy Charged With Manslaughter of T...     10\n",
       "45    #Bestnaijamade: 16yr old PKK suicide bomber wh...      6\n",
       "6131  The Prophet (peace be upon him) said 'Save you...      6\n",
       "3589  He came to a land which was engulfed in tribal...      6\n",
       "4589  Madhya Pradesh Train Derailment: Village Youth...      5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text = train_df.groupby('text').agg(count = ('target',len)).reset_index().sort_values('count', ascending=False)\n",
    "train_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa618ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[train_text['count']>1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2a176fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_texts = train_text['text'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e169e53",
   "metadata": {},
   "source": [
    "For some of these cases, there is also a mismatch in the target values - i.e. different instances of the same tweet have different taggings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b2a1e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7265</th>\n",
       "      <td>like for the music video I want some real acti...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>Hellfire! We donÛªt even want to think about ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>The Prophet (peace be upon him) said 'Save you...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>In #islam saving a person is equal in reward t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6353</th>\n",
       "      <td>To fight bioterrorism sir.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>Back from Seattle Tacoma and Portland. Whirlwi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>Baby elephant dies just days after surviving m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>BUT I will be uploading these videos ASAP so y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493</th>\n",
       "      <td>BREAKING: Terror Attack On\\nPolice Post #Udhampur</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7502</th>\n",
       "      <td>åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7503 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "7265  like for the music video I want some real acti...       2\n",
       "3618  Hellfire! We donÛªt even want to think about ...       2\n",
       "6131  The Prophet (peace be upon him) said 'Save you...       2\n",
       "4193  In #islam saving a person is equal in reward t...       2\n",
       "6353                         To fight bioterrorism sir.       2\n",
       "...                                                 ...     ...\n",
       "2496  Back from Seattle Tacoma and Portland. Whirlwi...       1\n",
       "2495  Baby elephant dies just days after surviving m...       1\n",
       "2494  BUT I will be uploading these videos ASAP so y...       1\n",
       "2493  BREAKING: Terror Attack On\\nPolice Post #Udhampur       1\n",
       "7502  åÈMGN-AFRICAå¨ pin:263789F4 åÈ Correction: Ten...       1\n",
       "\n",
       "[7503 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_unq_cnt = train_df.loc[train_df['text'].isin(dup_texts)].groupby('text')['target'].nunique().reset_index().sort_values('target', ascending=False)\n",
    "target_unq_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482dbd9e",
   "metadata": {},
   "source": [
    "These texts are eliminated from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd7f5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_target_list = target_unq_cnt.loc[target_unq_cnt['target']>1, 'text'].unique()\n",
    "train_df_clean = train_df.loc[~train_df['text'].isin(mismatch_target_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338306b",
   "metadata": {},
   "source": [
    "We also will eliminate any duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "630ac5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_clean = train_df_clean.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dde0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_clean.to_csv(data_folder.joinpath('train_clean.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b013aa8",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "237b9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(all_tokens, vocab_size):   \n",
    "    token_counts = Counter(all_tokens)   \n",
    "    token_counts = token_counts.most_common()[:vocab_size]   \n",
    "    vocab_list = ['<UNK>'] + [token for token, _ in token_counts]   \n",
    "    return vocab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec921da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = create_vocab(list(chain.from_iterable(train_df_clean['text'])), 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c55ffbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow (tokens, vocab, cvec):\n",
    "    cvec_counts = cvec.transform(tokens)\n",
    "    cvec_counts_bow = cvec_counts.toarray()\n",
    "    bow_model = pd.DataFrame(cvec_counts_bow, columns=vocab)\n",
    "    return bow_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d6f26e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2015' 'California' 'Full' 'Hiroshima' 'How' 'If' 'In' 'Is' 'It' 'My'\n",
      " 'New' 'News' 'RT' 'The' 'This' 'To' 'We' 'What' 'You' 'YouTube' 'about'\n",
      " 'after' 'all' 'amp' 'an' 'and' 'are' 'as' 'at' 'attack' 'back' 'be'\n",
      " 'been' 'body' 'bomb' 'buildings' 'burning' 'but' 'by' 'can' 'co' 'crash'\n",
      " 'day' 'disaster' 'do' 'don' 'down' 'fire' 'fires' 'for' 'for the' 'from'\n",
      " 'get' 'go' 'going' 'got' 'had' 'has' 'have' 'he' 'her' 'his' 'how' 'http'\n",
      " 'http co' 'https' 'https co' 'if' 'in' 'in the' 'into' 'is' 'it' 'just'\n",
      " 'killed' 'know' 'life' 'like' 'me' 'more' 'my' 'new' 'news' 'no' 'not'\n",
      " 'now' 'of' 'of the' 'off' 'old' 'on' 'on the' 'one' 'or' 'out' 'over'\n",
      " 'people' 're' 'see' 'so' 'some' 'still' 'suicide' 'than' 'that' 'the'\n",
      " 'their' 'them' 'there' 'they' 'this' 'time' 'to' 'to be' 'to the' 'today'\n",
      " 'up' 'via' 'video' 'was' 'we' 'were' 'what' 'when' 'who' 'will' 'with'\n",
      " 'would' 'year' 'you' 'your' 'Û_' 'Û_ http' 'Ûªs']\n"
     ]
    }
   ],
   "source": [
    "cvec = CountVectorizer(min_df = .01, max_df = .95, ngram_range=(1,2), lowercase=True)\n",
    "cvec.fit(train_df_clean['text'])\n",
    "vocab = cvec.get_feature_names_out() \n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45eb95fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2015</th>\n",
       "      <th>California</th>\n",
       "      <th>Full</th>\n",
       "      <th>Hiroshima</th>\n",
       "      <th>How</th>\n",
       "      <th>If</th>\n",
       "      <th>In</th>\n",
       "      <th>Is</th>\n",
       "      <th>It</th>\n",
       "      <th>My</th>\n",
       "      <th>...</th>\n",
       "      <th>who</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>Û_</th>\n",
       "      <th>Û_ http</th>\n",
       "      <th>Ûªs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7553</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7554</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7555</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7556</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7557</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7558 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      2015  California  Full  Hiroshima  How  If  In  Is  It  My  ...  who  \\\n",
       "0        0           0     0          0    0   0   0   0   0   0  ...    0   \n",
       "1        0           0     0          0    0   0   0   0   0   0  ...    0   \n",
       "2        0           0     0          0    0   0   0   0   0   0  ...    0   \n",
       "3        0           1     0          0    0   0   0   0   0   0  ...    0   \n",
       "4        0           0     0          0    0   0   0   0   0   0  ...    0   \n",
       "...    ...         ...   ...        ...  ...  ..  ..  ..  ..  ..  ...  ...   \n",
       "7553     0           0     0          0    0   0   0   0   0   0  ...    0   \n",
       "7554     0           1     0          0    0   0   0   0   0   0  ...    0   \n",
       "7555     0           0     0          0    0   0   0   0   0   0  ...    0   \n",
       "7556     0           0     0          0    0   0   0   0   0   0  ...    0   \n",
       "7557     0           1     0          0    0   0   0   0   0   0  ...    0   \n",
       "\n",
       "      will  with  would  year  you  your  Û_  Û_ http  Ûªs  \n",
       "0        0     0      0     0    0     0   0        0    0  \n",
       "1        0     0      0     0    0     0   0        0    0  \n",
       "2        0     0      0     0    0     0   0        0    0  \n",
       "3        0     0      0     0    0     0   0        0    0  \n",
       "4        0     0      0     0    0     0   0        0    0  \n",
       "...    ...   ...    ...   ...  ...   ...  ..      ...  ...  \n",
       "7553     0     0      0     0    0     0   0        0    0  \n",
       "7554     0     0      0     0    0     0   0        0    0  \n",
       "7555     0     0      0     0    0     0   0        0    0  \n",
       "7556     0     1      0     0    0     0   0        0    0  \n",
       "7557     0     0      0     0    0     0   0        0    0  \n",
       "\n",
       "[7558 rows x 134 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow(train_df_clean['text'], vocab, cvec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
